{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:52.626717Z",
     "start_time": "2024-03-23T13:58:51.434801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awswrangler in c:\\python38\\lib\\site-packages (3.7.3)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.32 in c:\\python38\\lib\\site-packages (from awswrangler) (1.34.91)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.32 in c:\\python38\\lib\\site-packages (from awswrangler) (1.34.91)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18 in c:\\python38\\lib\\site-packages (from awswrangler) (1.21.2)\n",
      "Requirement already satisfied: packaging<25.0,>=21.1 in c:\\python38\\lib\\site-packages (from awswrangler) (23.2)\n",
      "Requirement already satisfied: pandas<2.1.0,>=1.2.0 in c:\\python38\\lib\\site-packages (from awswrangler) (1.3.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\python38\\lib\\site-packages (from awswrangler) (14.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in c:\\python38\\lib\\site-packages (from awswrangler) (4.9.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\python38\\lib\\site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\python38\\lib\\site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\python38\\lib\\site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\python38\\lib\\site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (1.26.18)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\python38\\lib\\site-packages (from pandas<2.1.0,>=1.2.0->awswrangler) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python38\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.23.32->awswrangler) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\python38\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\python38\\lib\\site-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: colorlog in c:\\python38\\lib\\site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in c:\\python38\\lib\\site-packages (from optuna) (1.21.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python38\\lib\\site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\python38\\lib\\site-packages (from optuna) (2.0.25)\n",
      "Requirement already satisfied: tqdm in c:\\python38\\lib\\site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: PyYAML in c:\\python38\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in c:\\python38\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\python38\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\python38\\lib\\site-packages (from alembic>=1.5.0->optuna) (7.0.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\python38\\lib\\site-packages (from alembic>=1.5.0->optuna) (6.1.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python38\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\python38\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python38\\lib\\site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\python38\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "c:\\python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=minio\n",
      "env: AWS_SECRET_ACCESS_KEY=minio123\n",
      "env: MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
      "env: AWS_ENDPOINT_URL_S3=http://localhost:9000\n"
     ]
    }
   ],
   "source": [
    "!pip install awswrangler\n",
    "!pip install optuna\n",
    "\n",
    "import awswrangler as wr\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import datetime\n",
    "import optuna\n",
    "\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow_aux import get_or_create_experiment\n",
    "\n",
    "from optuna_aux import champion_callback, objective\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from plots import plot_correlation_with_target, plot_information_gain_with_target\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import awswrangler as wr\n",
    "\n",
    "import datetime\n",
    "#import optuna\n",
    "\n",
    "from mlflow.models import infer_signature\n",
    "#from mlflow_aux import get_or_create_experiment\n",
    "\n",
    "#from optuna_aux import champion_callback, objective\n",
    "\n",
    "\n",
    "\n",
    "# Optuna es un poco verboso, dejamos que solo nos muestre logs de errores\n",
    "#optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "\n",
    "# Optuna es un poco verboso, dejamos que solo nos muestre logs de errores\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# Para que funciones, todos nuestros scripts debemos exportar las siguientes variables de entorno\n",
    "%env AWS_ACCESS_KEY_ID=minio   \n",
    "%env AWS_SECRET_ACCESS_KEY=minio123 \n",
    "%env MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
    "%env AWS_ENDPOINT_URL_S3=http://localhost:9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_server = \"http://localhost:5000\"\n",
    "#mlflow_server = \"http://192.168.0.21:5000\"\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://data/final/test/mnist_784_y_test.csv'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_path = \"s3://data/raw/mnist_784.csv\"\n",
    "#dataframe = mnist_784_dataset.data.original\n",
    "\n",
    "#target_col = Variable.get(\"target_col_mnist_784\")\n",
    "\n",
    "mnist = fetch_openml('mnist_784', as_frame = False)\n",
    "\n",
    "dataframe = pd.DataFrame(mnist.data, columns=mnist.feature_names)\n",
    "target_col = pd.DataFrame(mnist.target, columns=['label'])\n",
    "\n",
    "dataframe['label'] = target_col['label']\n",
    "\n",
    "wr.s3.to_csv(df=dataframe,\n",
    "            path=\"s3://data/raw/mnist_784.csv\",\n",
    "            index=False)\n",
    "\n",
    "X_digits=dataframe.drop(['label'], axis=1)\n",
    "y_digits=dataframe['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits,\n",
    "                                                y_digits,\n",
    "                                                test_size=0.3,\n",
    "                                                random_state=32)\n",
    "\n",
    "# Dado que estamos usando como tracking a MLFlow, mostrar los gráficos aquí no tiene sentido.\n",
    "#correlation_plot = plot_correlation_with_target(X_train, y_train)\n",
    "#information_gain_plot = plot_information_gain_with_target(X_train, y_train)\n",
    "\n",
    "\n",
    "wr.s3.to_csv(df=X_train,\n",
    "            path=\"s3://data/final/train/mnist_784_X_train.csv\",\n",
    "            index=False)\n",
    "\n",
    "wr.s3.to_csv(df=X_test,\n",
    "            path=\"s3://data/final/test/mnist_784_X_test.csv\",\n",
    "            index=False)\n",
    "\n",
    "wr.s3.to_csv(df=y_train,\n",
    "            path=\"s3://data/final/train/mnist_784_y_train.csv\",\n",
    "            index=False)\n",
    "\n",
    "wr.s3.to_csv(df=y_test,\n",
    "            path=\"s3://data/final/test/mnist_784_y_test.csv\",\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsqueda de mejor modelo e hiperparámetros\n",
    "\n",
    "Dado nuestro dataset de mnist_784, el cual ya pasó por el proceso de ETL y se encuentra en nuestro S3 bucket, vamos a realizar una búsqueda de cual seria el mejor modelo y que hiperparametros usar.\n",
    "\n",
    "La búsqueda de hiperparametros la haremos usando Optuna y el tracking será realizado mediante MLFlow.\n",
    "\n",
    "OBS: Para la confección de esta notebook, nos basamos en el tutorial de [MLFlow](https://mlflow.org/docs/latest/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:53.919756Z",
     "start_time": "2024-03-23T13:58:53.345903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cargamos los datos para realizar nuestro estudio.\n",
    "# OBS, no vamos a cargar los datos de testing, nada de Data leakage por aquí\n",
    "X_train =  wr.s3.read_csv(\"s3://data/final/train/mnist_784_X_train.csv\").to_numpy()\n",
    "y_train =  wr.s3.read_csv(\"s3://data/final/train/mnist_784_y_train.csv\").to_numpy()\n",
    "\n",
    "X_test =  wr.s3.read_csv(\"s3://data/final/test/mnist_784_X_test.csv\").to_numpy()\n",
    "y_test =  wr.s3.read_csv(\"s3://data/final/test/mnist_784_y_test.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigamos la correlación de features con la variable objetivo\n",
    "\n",
    "Antes de profundizar en el proceso de construcción de modelo, es esencial comprender las relaciones entre nuestras features  y la variable objetivo. Por lo que vamos a realizar un gráfico que indica el coeficiente de correlación de cada feature en relación con la variable objetivo. Esto nos sirve para:\n",
    "\n",
    "- Evitar data leakage: Debemos asegurarnos de que ninguna característica se correlacione perfectamente con el objetivo (un coeficiente de correlación de aproximadamente 1.0). Si existe tal correlación, es una señal de que nuestro conjunto de datos podría estar \"filtrando\" información sobre el objetivo. \n",
    "\n",
    "- Garantizar relaciones significativas: Idealmente, nuestras características deberían tener algún grado de correlación con el objetivo. Inclusive si estamos trabajando con un problema de clasificación, aunque los resultados no son tan importantes como en un caso de regresión.\n",
    "\n",
    "- Auditoría y trazabilidad: Loggear esta visualización de correlación con nuestra ejecución principal de MLflow garantiza la trazabilidad. Proporciona una instantánea de las características de los datos en el momento del entrenamiento del modelo, lo cual es invaluable para propósitos de auditoría y replicabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:55.742436Z",
     "start_time": "2024-03-23T13:58:54.704687Z"
    }
   },
   "outputs": [],
   "source": [
    "#from plots import plot_correlation_with_target, plot_information_gain_with_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:55.925315Z",
     "start_time": "2024-03-23T13:58:55.743462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dado que estamos usando como tracking a MLFlow, mostrar los gráficos aquí no tiene sentido.\n",
    "#correlation_plot = plot_correlation_with_target(X_train, y_train)\n",
    "#information_gain_plot = plot_information_gain_with_target(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrancamos a experimentar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de poder realizar experimentos, vamos a crear el experimento en MLFLow, pero para evitar desorden, vamos a usar una función que se fije primero si el experimento existe, si esto es así, devuelve su ID.\n",
    "\n",
    "Además creamos el nombre del run padre con el que vamos a ir registrando las ejecuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:58:59.020326Z",
     "start_time": "2024-03-23T13:58:58.984334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Creemos el experimento\n",
    "experiment_id = get_or_create_experiment(\"mnist_784\")\n",
    "print(experiment_id)\n",
    "\n",
    "run_name_parent = \"best_hyperparam_\"  + datetime.datetime.today().strftime('%Y/%m/%d-%H:%M:%S\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con todo seteado, vamos a ejecutar la optimización usando Optuna, el cual realiza una búsqueda Bayesiana, la cual es más eficiente que una búsqueda de grilla tradicional. La desventaja es que es más difícil de paralelizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:43:38.917876Z",
     "start_time": "2024-03-23T13:43:06.961581Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'mnist_784_model_dev' already exists. Creating a new version of this model...\n",
      "2024/04/27 20:22:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: mnist_784_model_dev, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://mlflow/1/6059cf703acb4d48be9d61c849538926/artifacts/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'mnist_784_model_dev'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id, run_name=run_name_parent, nested=True):\n",
    "    # Inicializamos el estudio de Optuna\n",
    "\n",
    "    #artifact_path = \"s3://data/model\"\n",
    "    artifact_path = \"/model\"\n",
    "\n",
    "    #mlflow.log_artifact(\"features.txt\", artifact_path=artifact_path)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "    # Ejecutamos los trials de optimización de hiperparametros. Cada uno de estos trials se ejecuta con un run separado, pero \n",
    "    # está anidado al run padre.\n",
    "    # Notar la adición del `champion_callback` para controlar qué mensajes mostramos\n",
    "    # Para entender mejor esto ver la documentación de objective y champion_callback en optuna_aux\n",
    "    #study.optimize(lambda trial: objective(trial, X_train, y_train, experiment_id), n_trials=250, callbacks=[champion_callback])\n",
    "\n",
    "    # Una vez que terminamos la búsqueda, guardamos los mejores parámetros en el run padre.\n",
    "    #mlflow.log_params(study.best_params)\n",
    "    mlflow.log_params({'tree_max_depth':10})\n",
    "    #mlflow.log_metric(\"best_train_f1\", study.best_value)\n",
    "\n",
    "    mlflow.set_tags(\n",
    "        tags={\n",
    "            \"project\": \"mnist_784\",\n",
    "            #\"optimizer_engine\": \"optuna\",\n",
    "            \"model_family\": \"sklearn\",\n",
    "            \"feature_set_version\": 1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Una vez que terminamos la búsqueda, nos quedamos con el mejor modelo y lo entrenamos\n",
    "\n",
    "    model = DecisionTreeClassifier(criterion = 'entropy', max_depth=10)\n",
    "    #model = DecisionTreeClassifier(criterion = 'entropy', max_depth=study.best_params[\"tree_max_depth\"])\n",
    "\n",
    "\n",
    "    model = model.fit(X_train, y_train)\n",
    "\n",
    "    # Y testeamos el modelo y logueamos el resultado\n",
    "    y_pred = model.predict(X_test)\n",
    "    #f1_score = f1_score(y_test.to_numpy().ravel(), y_pred, average='weighted')\n",
    "    accuracy_score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    #mlflow.log_metric(\"test_f1\", f1_score)\n",
    "    mlflow.log_metric(\"test_accuracy_score\", accuracy_score)\n",
    "\n",
    "    # Logueamos los artefactos de las gráficas de correlación y de information_gain\n",
    "    #mlflow.log_figure(figure=correlation_plot, artifact_file=\"correlation_plot.png\")\n",
    "    #mlflow.log_figure(figure=information_gain_plot, artifact_file=\"information_gain_plot.png\")\n",
    "\n",
    "    # Guardamos el artefacto del modelo\n",
    "    #artifact_path = \"model\"\n",
    "\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=artifact_path,\n",
    "        signature=signature,\n",
    "        serialization_format='cloudpickle',\n",
    "        registered_model_name=\"mnist_784_model_dev\",\n",
    "        metadata={\"model_data_version\": 1}\n",
    "    )\n",
    "\n",
    "    # Obtenemos la ubicación del modelo guardado en MLFlow\n",
    "    model_uri = mlflow.get_artifact_uri(artifact_path)\n",
    "\n",
    "print(model_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testeando el modelo\n",
    "\n",
    "Una vez que el modelo fue entrenado, podemos levantarlo y testearlo de una forma agnóstica a donde está guardado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:52:48.990896Z",
     "start_time": "2024-03-23T13:52:48.840129Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: 'mnist_784_model_dev'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5884/4259289301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#loaded = mlflow.sklearn.load_model(model_uri)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mnist_784_model_dev\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(model_uri, dst_path)\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msk_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpandas_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \"\"\"\n\u001b[1;32m--> 613\u001b[1;33m     \u001b[0mlocal_model_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_download_artifact_from_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martifact_uri\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdst_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m     \u001b[0mflavor_conf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_flavor_configuration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_model_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflavor_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLAVOR_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m     \u001b[0m_add_code_from_conf_to_system_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_model_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflavor_conf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\mlflow\\tracking\\artifact_utils.py\u001b[0m in \u001b[0;36m_download_artifact_from_uri\u001b[1;34m(artifact_uri, output_path)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \"\"\"\n\u001b[0;32m     99\u001b[0m     \u001b[0mroot_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martifact_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_root_uri_and_artifact_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martifact_uri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0martifact_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     )\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\mlflow\\store\\artifact\\local_artifact_repo.py\u001b[0m in \u001b[0;36mdownload_artifacts\u001b[1;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mlocal_artifact_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0martifact_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_artifact_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"No such file or directory: '{local_artifact_path}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_artifact_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: No such file or directory: 'mnist_784_model_dev'"
     ]
    }
   ],
   "source": [
    "#loaded = mlflow.sklearn.load_model(model_uri)\n",
    "loaded = mlflow.sklearn.load_model(\"mnist_784_model_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:52:52.816010Z",
     "start_time": "2024-03-23T13:52:52.805948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/facundolucianna/Investigacion/env/notebook_env_python3_8/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_data = [-1.0431146438366603, 0.6689936080056726, 0.5955141571109206, 1.4218278518511829, -0.3955054753168235,\n",
    "             -0.195684619877533, 1.445528359737701, -0.8782783888787548, -0.4354941703556927, -0.6313862911472252,\n",
    "             1.0752906583803283, -0.0987729596649589, 0.957427107756338, 1.1071614388213236, -0.2991215208080594,\n",
    "             -0.5494422557947561, -0.362142984170074, 4.690415759823429, -0.2253029545296664, 1.1980376111153852]\n",
    "loaded.predict(np.array(test_data).reshape([1, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registramos el modelo \n",
    "\n",
    "Realizamos el registro del modelo en MLflow. En este registro se pone el modelo productivo que luego se usará para servir en formato on-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T13:53:33.534969Z",
     "start_time": "2024-03-23T13:53:33.462363Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/27 20:28:28 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: mnist_784_model_prod, version 1\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "name = \"mnist_784_model_prod\"\n",
    "desc = \"mnist_784\"\n",
    "\n",
    "# Creamos el modelo productivo\n",
    "client.create_registered_model(name=name, description=desc)\n",
    "\n",
    "# Guardamos como tag los hiper-parametros en la version del modelo\n",
    "tags = model.get_params()\n",
    "tags[\"model\"] = type(model).__name__\n",
    "tags[\"f1-score\"] = f1_score\n",
    "\n",
    "# Guardamos la version del modelo\n",
    "result = client.create_model_version(\n",
    "    name=name,\n",
    "    source=model_uri,\n",
    "    run_id=model_uri.split(\"/\")[-3],\n",
    "    tags=tags\n",
    ")\n",
    "\n",
    "# Y creamos como la version con el alias de champion para poder levantarlo en nuestro\n",
    "# proceso de servicio del modelo on-line.\n",
    "client.set_registered_model_alias(name, \"champion\", result.version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
